from concurrent.futures import ThreadPoolExecutor
from typing_extensions import Literal
import os

from api.models import ChatMessage
from bot.model_selector import ENABLED_MODELS, ENABLED_TOOLS, generate_embeddings, predict_model
from bot.openai_utils import DEFAULT_CHAT_MODEL, ChatCompletion, handle_negative_feedback, trim_chat_frame
from bot.v1 import chat as v1_chat
from db.models import MessageReplied, SessionLocal
from observability.logging import logging

executor = ThreadPoolExecutor(max_workers=os.getenv("MAX_EXECUTOR_WORKERS", 1))
logger = logging.getLogger(__name__)


def chat(messages: list[ChatMessage],
         system_message: str = None,
         temperature: float = 0.0,
         tools: dict[str, dict] = None,
         tool_choice: Literal['auto', 'none'] = 'none') -> object:
    new_chat_message: ChatMessage = messages[-1]
    logger.debug("received: %s", new_chat_message.content)

    # Start background tasks
    future_negative_feedback_completion = executor.submit(
        handle_negative_feedback,
        trim_chat_frame(messages, DEFAULT_CHAT_MODEL, system_message=system_message),
        ENABLED_TOOLS)

    # Generate embeddings
    embeddings = generate_embeddings(new_chat_message.content)

    # Predict the best model
    model = ENABLED_MODELS[predict_model(embeddings)]
    logger.info("predicted model: %s", model)

    ##
    # TODO: reinforcement learning based selection >>HERE<<
    #   - frequency_penalty, Optional, Defaults to 0,  Number between -2.0 and 2.0. Positive values penalize new
    #     tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat
    #     the same line verbatim.
    #   - logit_bias, Optional, Defaults to null, Accepts a JSON object that maps tokens (specified by their token
    #     ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to
    #     the logits generated by the model prior to sampling. The exact effect will vary per model, but values
    #     between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should
    #     result in a ban or exclusive selection of the relevant token.
    #   - presence_penalty, Optional, Defaults to 0, Number between -2.0 and 2.0. Positive values penalize new
    #     tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about
    #     new topics.
    #   - temperature, Optional, Defaults to 1, What sampling temperature to use, between 0 and 2. Higher values
    #     like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and
    #     deterministic. Generally, alter this or top_p but not both.
    #   - top_p, Optional, Defaults to 1, An alternative to sampling with temperature, called nucleus sampling,
    #     where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the
    #     tokens comprising the top 10% probability mass are considered. Generally, alter this or temperature but
    #     not both.
    #
    # Ref: https://platform.openai.com/docs/api-reference/chat/create

    chat_response = v1_chat(messages,
                            model=model,
                            system_message=system_message,
                            temperature=temperature,
                            tools=tools,
                            tool_choice=tool_choice)
    negative_feedback_completion: ChatCompletion = future_negative_feedback_completion.result()
    # If the user is providing negative feedback, don't use the normal chat response.
    if negative_feedback_completion.choices[0].message.tool_calls:
        with SessionLocal() as session:
            message_replied = session.query(MessageReplied).filter(
                MessageReplied.id == chat_response.message_replied_id).first()
            if message_replied:
                message_replied.content = negative_feedback_completion.choices[0].message.content.encode('utf-8')
                message_replied.tool_calls = [
                    c.dict() for c in negative_feedback_completion.choices[0].message.tool_calls
                ]
            session.commit()
        chat_response.response = negative_feedback_completion
        return chat_response
    else:
        return chat_response
